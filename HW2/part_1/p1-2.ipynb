{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "import copy\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "def load_train_data():\n",
    "    X_train = None\n",
    "    Y_train = None\n",
    "    for i in range(1, 6):\n",
    "        pickleFile = unpickle('cifar-10-batches-py/data_batch_{}'.format(i))\n",
    "        dataX = pickleFile[b'data']\n",
    "        dataY = pickleFile[b'labels']\n",
    "        if type(X_train) is np.ndarray:\n",
    "            X_train = np.concatenate((X_train, dataX))\n",
    "            Y_train = np.concatenate((Y_train, dataY))\n",
    "        else:\n",
    "            X_train = dataX\n",
    "            Y_train = dataY\n",
    "\n",
    "    Y_train = Y_train.reshape(Y_train.shape[0], 1)\n",
    "\n",
    "    return X_train.T, Y_train.T\n",
    "\n",
    "def load_test_data():\n",
    "    X_test = None\n",
    "    Y_test = None\n",
    "    pickleFile = unpickle('cifar-10-batches-py/test_batch')\n",
    "    dataX = pickleFile[b'data']\n",
    "    dataY = pickleFile[b'labels']\n",
    "    if type(X_test) is np.ndarray:\n",
    "        X_test = np.concatenate((X_test, dataX))\n",
    "        Y_test = np.concatenate((Y_test, dataY))\n",
    "    else:\n",
    "        X_test = np.array(dataX)\n",
    "        Y_test = np.array(dataY)\n",
    "\n",
    "    Y_test = Y_test.reshape(Y_test.shape[0], 1)\n",
    "\n",
    "    return X_test.T, Y_test.T\n",
    "\n",
    "def train_test_split(X_train, Y_train):\n",
    "    msk = np.random.rand(Y_train.shape[1]) < 0.8\n",
    "    X_Train = X_train[:,msk]  \n",
    "    X_val = X_train[:,~msk]\n",
    "    Y_Train = Y_train[:,msk]  \n",
    "    Y_val = Y_train[:,~msk]\n",
    "\n",
    "    return X_Train, Y_Train, X_val, Y_val\n",
    "\n",
    "def get_batch(X, Y, batch_size):\n",
    "    n_batches = int(Y.shape[1]/batch_size)\n",
    "    idx = np.arange(Y.shape[1])\n",
    "    np.random.shuffle(idx)\n",
    "    \n",
    "    ret = []\n",
    "    for i in range(0,int(len(idx)/batch_size)):\n",
    "        chunk = idx[i*batch_size:(i+1)*batch_size]\n",
    "        ret.append(chunk)\n",
    "    mini = ret\n",
    "    \n",
    "    return mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3)\n",
    "        self.conv2_drop = nn.Dropout2d(0.25)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3)\n",
    "        self.conv4 = nn.Conv2d(64,64,3)\n",
    "        self.fc1 = nn.Linear(64 * 5 * 5, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool(F.relu(self.conv4(x)))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = x.view(-1, 64 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,Y_train = load_train_data()\n",
    "X_test, Y_test = load_test_data()\n",
    "X_Train, Y_Train, X_Val, Y_Val = train_test_split(X_train,Y_train)\n",
    "\n",
    "minn = np.min(X_Train, axis=1,keepdims=True)\n",
    "maxx = np.max(X_Train, axis=1,keepdims=True)\n",
    "X_Train= (X_Train - minn)/(maxx-minn)\n",
    "X_Val= (X_Val - minn)/(maxx-minn)\n",
    "X_Test= (X_test - minn)/(maxx-minn)\n",
    "\n",
    "net = Net().cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "optimizer = optim.RMSprop(net.parameters(), lr=0.0001, weight_decay=1e-6)#, momentum=0.9)\n",
    "\n",
    "def test_acc():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    idx = get_batch(X_Test, Y_test, batch_size_len)\n",
    "\n",
    "    for idx_list in idx:\n",
    "        x_batch_test = [X_Test.T[index] for index in idx_list]\n",
    "        y_batch_test = [Y_test.T[index] for index in idx_list]\n",
    "        x_batch_test = np.asarray(x_batch_test)\n",
    "        y_batch_test1 = np.asarray(y_batch_test)\n",
    "        y_batch_onehot_test = get_one_hot(y_batch_test1,10)\n",
    "        label_tensor_test = torch.from_numpy(y_batch_onehot_test)\n",
    "        test_labels = Variable(label_tensor_test.cuda()).long()\n",
    "        true_labels = torch.max(test_labels,1)[1]\n",
    "        x_batch_test = x_batch_test.reshape(x_batch_test.shape[0],3,32,32)    \n",
    "        input_tensor_test = torch.from_numpy(x_batch_test)\n",
    "        images = Variable(input_tensor_test.cuda()).float()\n",
    "        outputs = net(images)\n",
    "        ##### loss = criterion(outputs, torch.max(labels, 1)[1])\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == true_labels.data.long()).sum()\n",
    "    \n",
    "    return (100 * correct / total)\n",
    "\n",
    "def get_one_hot(targets, nb_classes):\n",
    "    return np.eye(nb_classes)[np.array(targets).reshape(-1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n",
      "Epoch 1 Count: 300 loss: 5.821441228049142 \t 284 loss_val: 14.561085895129613\n",
      "Epoch 2 Count: 300 loss: 4.902991437911988 \t 284 loss_val: 13.337861786569867\n",
      "Epoch 3 Count: 300 loss: 4.5138116461890085 \t 284 loss_val: 12.565077757835388\n",
      "Epoch 4 Count: 300 loss: 4.2919711521693635 \t 284 loss_val: 12.072645139694213\n",
      "Epoch 5 Count: 300 loss: 4.13318635736193 \t 284 loss_val: 11.5909624508449\n",
      "Epoch 6 Count: 300 loss: 4.084623071125575 \t 284 loss_val: 11.485970170157296\n",
      "Epoch 7 Count: 300 loss: 3.843332621029445 \t 284 loss_val: 11.021020708765302\n",
      "Epoch 8 Count: 300 loss: 3.6899456909724644 \t 284 loss_val: 10.790792300019945\n",
      "Epoch 9 Count: 300 loss: 3.670829451084137 \t 284 loss_val: 10.423031529358456\n",
      "Epoch 10 Count: 300 loss: 3.6041606187820436 \t 284 loss_val: 10.29826123033251\n",
      "Epoch 11 Count: 300 loss: 3.501607607092176 \t 284 loss_val: 10.102875792980194\n",
      "Epoch 12 Count: 300 loss: 3.4768303496497017 \t 284 loss_val: 10.135044160911015\n",
      "Epoch 13 Count: 300 loss: 3.385333127634866 \t 284 loss_val: 9.812001943588257\n",
      "Epoch 14 Count: 300 loss: 3.2889377815382823 \t 284 loss_val: 9.552274692058564\n",
      "Epoch 15 Count: 300 loss: 3.176108658313751 \t 284 loss_val: 9.398276037829262\n",
      "Epoch 16 Count: 300 loss: 3.1405883056776864 \t 284 loss_val: 9.3837291768619\n",
      "Epoch 17 Count: 300 loss: 3.0928693567003522 \t 284 loss_val: 9.231769820622036\n",
      "Epoch 18 Count: 300 loss: 3.0265056201389857 \t 284 loss_val: 8.957259289707457\n",
      "Epoch 19 Count: 300 loss: 2.966609983784812 \t 284 loss_val: 9.008776620456151\n",
      "Epoch 20 Count: 300 loss: 2.958913803100586 \t 284 loss_val: 8.95677534852709\n",
      "Epoch 21 Count: 300 loss: 2.8713049735341754 \t 284 loss_val: 8.770723516600473\n",
      "Epoch 22 Count: 300 loss: 2.948007084642138 \t 284 loss_val: 9.051231612477984\n",
      "Epoch 23 Count: 300 loss: 2.767762075151716 \t 284 loss_val: 8.726729944774084\n",
      "Epoch 24 Count: 300 loss: 2.721503680092948 \t 284 loss_val: 8.452699169090815\n",
      "Epoch 25 Count: 300 loss: 2.694689166545868 \t 284 loss_val: 8.493461040088109\n",
      "Epoch 26 Count: 300 loss: 2.656378105708531 \t 284 loss_val: 8.38983894416264\n",
      "Epoch 27 Count: 300 loss: 2.594787452902113 \t 284 loss_val: 8.26830622298377\n",
      "Epoch 28 Count: 300 loss: 2.774204923425402 \t 284 loss_val: 8.306188472679683\n",
      "Epoch 29 Count: 300 loss: 2.603247262750353 \t 284 loss_val: 8.333261185032981\n",
      "Epoch 30 Count: 300 loss: 2.601515861068453 \t 284 loss_val: 8.29863202231271\n",
      "Epoch 31 Count: 300 loss: 2.5378910626683915 \t 284 loss_val: 8.090017815998623\n",
      "Epoch 32 Count: 300 loss: 2.487560374396188 \t 284 loss_val: 8.168319632325854\n",
      "Epoch 33 Count: 300 loss: 2.5303259883608136 \t 284 loss_val: 8.002486673423222\n",
      "Epoch 34 Count: 300 loss: 2.4257015398570467 \t 284 loss_val: 7.946568772622517\n",
      "Epoch 35 Count: 300 loss: 2.43629395876612 \t 284 loss_val: 7.98142877306257\n",
      "Epoch 36 Count: 300 loss: 2.3861931221825734 \t 284 loss_val: 7.9999568275042945\n",
      "Epoch 37 Count: 300 loss: 2.489618568761008 \t 284 loss_val: 7.972947818892343\n",
      "Epoch 38 Count: 300 loss: 2.4273436282362257 \t 284 loss_val: 7.810645604133606\n",
      "Epoch 39 Count: 300 loss: 2.3274025176252637 \t 284 loss_val: 7.781179374456405\n",
      "Epoch 40 Count: 300 loss: 2.3733412223202843 \t 284 loss_val: 7.701530969994408\n",
      "Epoch 41 Count: 300 loss: 2.310617733001709 \t 284 loss_val: 7.812754944392613\n",
      "Epoch 42 Count: 300 loss: 2.392398931298937 \t 284 loss_val: 7.648566667522703\n",
      "Epoch 43 Count: 300 loss: 2.2919368394783564 \t 284 loss_val: 7.603866163321904\n",
      "Epoch 44 Count: 300 loss: 2.242058117900576 \t 284 loss_val: 7.615169356550489\n",
      "Epoch 45 Count: 300 loss: 2.2782047518662045 \t 284 loss_val: 7.626814338139125\n",
      "Epoch 46 Count: 300 loss: 2.2183472735541208 \t 284 loss_val: 7.681159979104995\n",
      "Epoch 47 Count: 300 loss: 2.1914251020976474 \t 284 loss_val: 7.6076736237321585\n",
      "Epoch 48 Count: 300 loss: 2.1427807927131655 \t 284 loss_val: 7.469873976707459\n",
      "Epoch 49 Count: 300 loss: 2.1162138019289287 \t 284 loss_val: 7.562312149150031\n",
      "Epoch 50 Count: 300 loss: 2.157487226384027 \t 284 loss_val: 7.3463469888482775\n",
      "Epoch 51 Count: 300 loss: 2.0899392562253136 \t 284 loss_val: 7.563540300301143\n",
      "Epoch 52 Count: 300 loss: 2.0235601544380186 \t 284 loss_val: 7.4205344847270425\n",
      "Epoch 53 Count: 300 loss: 2.1339053613798957 \t 284 loss_val: 7.406538940327508\n",
      "Epoch 54 Count: 300 loss: 2.09197809951646 \t 284 loss_val: 7.365693562371391\n",
      "Epoch 55 Count: 300 loss: 2.0919553441660743 \t 284 loss_val: 7.263117682082313\n",
      "Epoch 56 Count: 300 loss: 2.0302649089268274 \t 284 loss_val: 7.393626870427813\n",
      "Epoch 57 Count: 300 loss: 2.0275103505168643 \t 284 loss_val: 7.31762244275638\n",
      "Epoch 58 Count: 300 loss: 2.029135353224618 \t 284 loss_val: 7.298573780059814\n",
      "Epoch 59 Count: 300 loss: 2.045853328704834 \t 284 loss_val: 7.338690066337586\n",
      "Epoch 60 Count: 300 loss: 1.9845316691058024 \t 284 loss_val: 7.14733332821301\n",
      "Epoch 61 Count: 300 loss: 2.0784556840147292 \t 284 loss_val: 7.308745737586703\n",
      "Epoch 62 Count: 300 loss: 1.9825697984014239 \t 284 loss_val: 7.2730444967746735\n",
      "Epoch 63 Count: 300 loss: 1.904154599564416 \t 284 loss_val: 7.268157570702689\n",
      "Epoch 64 Count: 300 loss: 1.9068551966122218 \t 284 loss_val: 7.322204153878348\n",
      "Epoch 65 Count: 300 loss: 1.9031126056398664 \t 284 loss_val: 7.06368345447949\n",
      "Epoch 66 Count: 300 loss: 2.0055285734789714 \t 284 loss_val: 7.087175793307168\n",
      "Epoch 67 Count: 300 loss: 2.003017874274935 \t 284 loss_val: 7.228385243245533\n",
      "Epoch 68 Count: 300 loss: 1.8556698066847666 \t 284 loss_val: 7.095629974773952\n",
      "Epoch 69 Count: 300 loss: 1.7994148467268263 \t 284 loss_val: 6.988517019578389\n",
      "Epoch 70 Count: 300 loss: 1.8489126196929386 \t 284 loss_val: 7.089466685908182\n",
      "Epoch 71 Count: 300 loss: 1.892221795661109 \t 284 loss_val: 7.2337310126849586\n",
      "Epoch 72 Count: 300 loss: 1.869911996807371 \t 284 loss_val: 7.26208439384188\n",
      "Epoch 73 Count: 300 loss: 1.8704574823379516 \t 284 loss_val: 7.065765166282654\n",
      "Epoch 74 Count: 300 loss: 1.7627715766429901 \t 284 loss_val: 7.0841286437852045\n",
      "Epoch 75 Count: 300 loss: 1.8448403673512594 \t 284 loss_val: 7.011289027759007\n",
      "Epoch 76 Count: 300 loss: 1.8152647580419268 \t 284 loss_val: 6.950700038671494\n",
      "Epoch 77 Count: 300 loss: 1.838502209527152 \t 284 loss_val: 7.113576165267399\n",
      "Epoch 78 Count: 300 loss: 1.8735045518193927 \t 284 loss_val: 6.820679235458374\n",
      "Epoch 79 Count: 300 loss: 1.8290215594427925 \t 284 loss_val: 7.1514683970383235\n",
      "Epoch 80 Count: 300 loss: 1.8703522878033774 \t 284 loss_val: 7.161829836027962\n",
      "Epoch 81 Count: 300 loss: 1.7952769185815538 \t 284 loss_val: 6.936278351715633\n",
      "Epoch 82 Count: 300 loss: 1.7564586188111986 \t 284 loss_val: 6.829709827899933\n",
      "Epoch 83 Count: 300 loss: 1.7355052249772207 \t 284 loss_val: 6.9790807749543875\n",
      "Epoch 84 Count: 300 loss: 1.7625744606767382 \t 284 loss_val: 6.819513955286571\n",
      "Epoch 85 Count: 300 loss: 1.815657149893897 \t 284 loss_val: 6.887014199154717\n",
      "Epoch 86 Count: 300 loss: 1.7078415845121657 \t 284 loss_val: 7.027720671892166\n",
      "Epoch 87 Count: 300 loss: 1.7727323702403477 \t 284 loss_val: 6.878266733033317\n",
      "Epoch 88 Count: 300 loss: 1.8172731280326844 \t 284 loss_val: 6.935082521608898\n",
      "Epoch 89 Count: 300 loss: 1.7719046030725751 \t 284 loss_val: 6.993104704788753\n",
      "Epoch 90 Count: 300 loss: 1.6947605047907148 \t 284 loss_val: 7.062668285199574\n",
      "Epoch 91 Count: 300 loss: 1.606946666751589 \t 284 loss_val: 6.88296423298972\n",
      "Epoch 92 Count: 300 loss: 1.6680321420942035 \t 284 loss_val: 6.900442062105451\n",
      "Epoch 93 Count: 300 loss: 1.6970525034836361 \t 284 loss_val: 6.878227639198303\n",
      "Epoch 94 Count: 300 loss: 1.602310803106853 \t 284 loss_val: 6.9101146604333605\n",
      "Epoch 95 Count: 300 loss: 1.6676557374852043 \t 284 loss_val: 7.101966576065336\n",
      "Epoch 96 Count: 300 loss: 1.6957270145416259 \t 284 loss_val: 6.921360014166151\n",
      "Epoch 97 Count: 300 loss: 1.6175406353814261 \t 284 loss_val: 6.926747512817383\n",
      "Epoch 98 Count: 300 loss: 1.7188324161938258 \t 284 loss_val: 6.895349337373461\n",
      "Epoch 99 Count: 300 loss: 1.6561800360679626 \t 284 loss_val: 6.908662133557456\n",
      "Epoch 100 Count: 300 loss: 1.7027451000043323 \t 284 loss_val: 7.0760228633880615\n",
      "Epoch 101 Count: 300 loss: 1.6191746809652874 \t 284 loss_val: 6.835797228983471\n",
      "Epoch 102 Count: 300 loss: 1.6361576208046504 \t 284 loss_val: 7.00950476867812\n",
      "Epoch 103 Count: 300 loss: 1.6435351993356433 \t 284 loss_val: 6.896537750959396\n",
      "Epoch 104 Count: 300 loss: 1.6467610376221793 \t 284 loss_val: 6.842574214935302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105 Count: 300 loss: 1.5638075113296508 \t 284 loss_val: 6.953010730232511\n",
      "Epoch 106 Count: 300 loss: 1.5588037363120488 \t 284 loss_val: 6.861579972505569\n",
      "Epoch 107 Count: 300 loss: 1.6460472400699342 \t 284 loss_val: 6.89587989790099\n",
      "Epoch 108 Count: 300 loss: 1.5770435231072562 \t 284 loss_val: 6.768211507797242\n",
      "Epoch 109 Count: 300 loss: 1.5998867298875536 \t 284 loss_val: 7.026811185904911\n",
      "Epoch 110 Count: 300 loss: 1.6015595074210849 \t 284 loss_val: 6.75294006552015\n",
      "Epoch 111 Count: 300 loss: 1.4785381742886134 \t 284 loss_val: 6.894334059102195\n",
      "Epoch 112 Count: 300 loss: 1.5697358944586346 \t 284 loss_val: 6.8814749828406745\n",
      "Epoch 113 Count: 300 loss: 1.5943581406559264 \t 284 loss_val: 6.7400772869586945\n",
      "Epoch 114 Count: 300 loss: 1.587717831986291 \t 284 loss_val: 6.795309620244162\n",
      "Epoch 115 Count: 300 loss: 1.6180994434016092 \t 284 loss_val: 6.8398306284632\n",
      "Epoch 116 Count: 300 loss: 1.5633635776383537 \t 284 loss_val: 6.869571255786078\n",
      "Epoch 117 Count: 300 loss: 1.5785909120525632 \t 284 loss_val: 6.956402577246938\n",
      "Epoch 118 Count: 300 loss: 1.5785194209643774 \t 284 loss_val: 6.819162537370409\n",
      "Epoch 119 Count: 300 loss: 1.5123409573520934 \t 284 loss_val: 6.933471219028745\n",
      "Epoch 120 Count: 300 loss: 1.5069357880524226 \t 284 loss_val: 6.8500903836318425\n",
      "Epoch 121 Count: 300 loss: 1.568282425403595 \t 284 loss_val: 6.791726982593536\n",
      "Epoch 122 Count: 300 loss: 1.5491796272141594 \t 284 loss_val: 6.851378927912031\n",
      "Epoch 123 Count: 300 loss: 1.498738757627351 \t 284 loss_val: 6.870295142275946\n",
      "Epoch 124 Count: 300 loss: 1.5212673736470086 \t 284 loss_val: 6.805947942393167\n",
      "Epoch 125 Count: 300 loss: 1.6003871538809367 \t 284 loss_val: 6.7872896015644075\n",
      "Epoch 126 Count: 300 loss: 1.520679068991116 \t 284 loss_val: 6.858135780266353\n",
      "Epoch 127 Count: 300 loss: 1.4994099242346628 \t 284 loss_val: 6.976572109120233\n",
      "Epoch 128 Count: 300 loss: 1.4801843485661916 \t 284 loss_val: 6.807887553317206\n",
      "Epoch 129 Count: 300 loss: 1.444938211781638 \t 284 loss_val: 6.809927411590304\n",
      "Epoch 130 Count: 300 loss: 1.5207053908279964 \t 284 loss_val: 6.997798322779792\n",
      "Epoch 131 Count: 300 loss: 1.5426417997905186 \t 284 loss_val: 6.856145881755012\n",
      "Epoch 132 Count: 300 loss: 1.6010574855974742 \t 284 loss_val: 6.934818177563804\n",
      "Epoch 133 Count: 300 loss: 1.5141654687268393 \t 284 loss_val: 6.845216401985714\n",
      "Epoch 134 Count: 300 loss: 1.5104620337486268 \t 284 loss_val: 6.783441775185722\n",
      "Epoch 135 Count: 300 loss: 1.5137721615178243 \t 284 loss_val: 6.930291434696742\n",
      "Epoch 136 Count: 300 loss: 1.491344370160784 \t 284 loss_val: 6.746167354924339\n",
      "Epoch 137 Count: 300 loss: 1.4865351395947592 \t 284 loss_val: 6.825145086220332\n",
      "Epoch 138 Count: 300 loss: 1.4702854113919395 \t 284 loss_val: 6.8571299867970605\n",
      "Epoch 139 Count: 300 loss: 1.50757129575525 \t 284 loss_val: 6.819278332165309\n",
      "Epoch 140 Count: 300 loss: 1.5081355725015912 \t 284 loss_val: 6.8292063253266475\n",
      "Epoch 141 Count: 300 loss: 1.4820621371269227 \t 284 loss_val: 6.951474523544311\n",
      "Epoch 142 Count: 300 loss: 1.5499879509210586 \t 284 loss_val: 6.7973002587045945\n",
      "Epoch 143 Count: 300 loss: 1.5514346859284809 \t 284 loss_val: 6.974084437744958\n",
      "Epoch 144 Count: 300 loss: 1.4524065669093813 \t 284 loss_val: 6.771590820806367\n",
      "Epoch 145 Count: 300 loss: 1.4320468766348702 \t 284 loss_val: 6.821202224493026\n",
      "Epoch 146 Count: 300 loss: 1.5182593141283307 \t 284 loss_val: 6.713540749038969\n",
      "Epoch 147 Count: 300 loss: 1.4828321801764623 \t 284 loss_val: 6.860272571444511\n",
      "Epoch 148 Count: 300 loss: 1.4184576558215278 \t 284 loss_val: 6.647598475643567\n",
      "Epoch 149 Count: 300 loss: 1.4289740528379167 \t 284 loss_val: 6.765346597773688\n",
      "Epoch 150 Count: 300 loss: 1.5115165642329624 \t 284 loss_val: 6.588268924610955\n",
      "Epoch 151 Count: 300 loss: 1.4990341680390493 \t 284 loss_val: 6.869595297745296\n",
      "Epoch 152 Count: 300 loss: 1.478621978844915 \t 284 loss_val: 6.862445808308465\n",
      "Epoch 153 Count: 300 loss: 1.4108852526971272 \t 284 loss_val: 7.012096055064883\n",
      "Epoch 154 Count: 300 loss: 1.3530530806098666 \t 284 loss_val: 6.764097194160734\n",
      "Epoch 155 Count: 300 loss: 1.4977183767727442 \t 284 loss_val: 6.821567456211363\n",
      "Epoch 156 Count: 300 loss: 1.492008494053568 \t 284 loss_val: 6.899897179433277\n",
      "Epoch 157 Count: 300 loss: 1.4645277623619353 \t 284 loss_val: 6.931415956786701\n",
      "Epoch 158 Count: 300 loss: 1.4208417794534138 \t 284 loss_val: 6.937867820688656\n",
      "Epoch 159 Count: 300 loss: 1.4263740522520882 \t 284 loss_val: 6.770776257344655\n",
      "Epoch 160 Count: 300 loss: 1.431000035575458 \t 284 loss_val: 6.769674753291266\n",
      "Epoch 161 Count: 300 loss: 1.4915441359792436 \t 284 loss_val: 6.993880499260766\n",
      "Epoch 162 Count: 300 loss: 1.4039669828755514 \t 284 loss_val: 6.918911754659244\n",
      "Epoch 163 Count: 300 loss: 1.5316832597766603 \t 284 loss_val: 6.739288589784077\n",
      "Epoch 164 Count: 300 loss: 1.4084613450935908 \t 284 loss_val: 6.7840162021773205\n",
      "Epoch 165 Count: 300 loss: 1.4332965527262007 \t 284 loss_val: 6.977102656023843\n",
      "Epoch 166 Count: 300 loss: 1.4699630234922683 \t 284 loss_val: 6.892167737654277\n",
      "Epoch 167 Count: 300 loss: 1.4346751264163426 \t 284 loss_val: 7.080813675267356\n",
      "Epoch 168 Count: 300 loss: 1.3724636963435581 \t 284 loss_val: 6.979311035786356\n",
      "Epoch 169 Count: 300 loss: 1.4459393663065774 \t 284 loss_val: 6.811281549930572\n",
      "Epoch 170 Count: 300 loss: 1.3606509600366865 \t 284 loss_val: 6.987502933400018\n",
      "Epoch 171 Count: 300 loss: 1.4475603048290526 \t 284 loss_val: 6.91098683306149\n",
      "Epoch 172 Count: 300 loss: 1.3949639133044651 \t 284 loss_val: 6.9712555783135555\n",
      "Epoch 173 Count: 300 loss: 1.4099042637007577 \t 284 loss_val: 6.922148178304945\n",
      "Epoch 174 Count: 300 loss: 1.3574598142078944 \t 284 loss_val: 7.079086572783334\n",
      "Epoch 175 Count: 300 loss: 1.4049808455365045 \t 284 loss_val: 7.1076517581939695\n",
      "Epoch 176 Count: 300 loss: 1.4646596023014613 \t 284 loss_val: 6.951281903897013\n",
      "Epoch 177 Count: 300 loss: 1.4270340306418283 \t 284 loss_val: 6.773320480755397\n",
      "Epoch 178 Count: 300 loss: 1.4409403247492654 \t 284 loss_val: 6.7835386050598965\n",
      "Epoch 179 Count: 300 loss: 1.3924155793019704 \t 284 loss_val: 6.863404892172132\n",
      "Epoch 180 Count: 300 loss: 1.4642448323113577 \t 284 loss_val: 6.856193573134286\n",
      "Epoch 181 Count: 300 loss: 1.5036628480468477 \t 284 loss_val: 7.01711685870375\n",
      "Epoch 182 Count: 300 loss: 1.4228924653359822 \t 284 loss_val: 6.9212905364377155\n",
      "Epoch 183 Count: 300 loss: 1.3430149508374079 \t 284 loss_val: 6.962223445943423\n",
      "Epoch 184 Count: 300 loss: 1.413665583729744 \t 284 loss_val: 6.855372542142868\n",
      "Epoch 185 Count: 300 loss: 1.3292931241648538 \t 284 loss_val: 7.008160666057042\n",
      "Epoch 186 Count: 300 loss: 1.46171658379691 \t 284 loss_val: 6.903651664512498\n",
      "Epoch 187 Count: 300 loss: 1.3561253773314612 \t 284 loss_val: 7.116375487191337\n",
      "Epoch 188 Count: 300 loss: 1.418994791167123 \t 284 loss_val: 6.74256526018892\n",
      "Epoch 189 Count: 300 loss: 1.4122355146067482 \t 284 loss_val: 6.98804623229163\n",
      "Epoch 190 Count: 300 loss: 1.456301191874913 \t 284 loss_val: 6.790985045262746\n",
      "Epoch 191 Count: 300 loss: 1.400173177889415 \t 284 loss_val: 6.836914725814547\n",
      "Epoch 192 Count: 300 loss: 1.4049076889242444 \t 284 loss_val: 6.939052900246211\n",
      "Epoch 193 Count: 300 loss: 1.4652396989720209 \t 284 loss_val: 7.002842351368495\n",
      "Epoch 194 Count: 300 loss: 1.3700417063065937 \t 284 loss_val: 6.989498800039291\n",
      "Epoch 195 Count: 300 loss: 1.3962794491222927 \t 284 loss_val: 6.755233146463122\n",
      "Epoch 196 Count: 300 loss: 1.4000560049499784 \t 284 loss_val: 6.719065552949905\n",
      "Epoch 197 Count: 300 loss: 1.3732743829488754 \t 284 loss_val: 6.742094332831247\n",
      "Epoch 198 Count: 300 loss: 1.3941927037068775 \t 284 loss_val: 6.997323821272169\n",
      "Epoch 199 Count: 300 loss: 1.3653717705181667 \t 284 loss_val: 6.870622481618609\n",
      "Epoch 200 Count: 300 loss: 1.3320328216467585 \t 284 loss_val: 6.87083312528474\n",
      "Epoch 201 Count: 300 loss: 1.4151191281420843 \t 284 loss_val: 6.679411825111934\n",
      "Epoch 202 Count: 300 loss: 1.2834320383412496 \t 284 loss_val: 6.893920880556107\n",
      "Epoch 203 Count: 300 loss: 1.3739469932658332 \t 284 loss_val: 6.8802261825118745\n",
      "Epoch 204 Count: 300 loss: 1.382657499398504 \t 284 loss_val: 6.8196731780256545\n",
      "Epoch 205 Count: 300 loss: 1.3819375919444221 \t 284 loss_val: 6.916908034256527\n",
      "Epoch 206 Count: 300 loss: 1.3634970379727227 \t 284 loss_val: 6.954410758188793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 207 Count: 300 loss: 1.3526933755193438 \t 284 loss_val: 6.698261518137795\n",
      "Epoch 208 Count: 300 loss: 1.4074900874069758 \t 284 loss_val: 6.785219476904188\n",
      "Epoch 209 Count: 300 loss: 1.4303264771189008 \t 284 loss_val: 6.850055382932935\n",
      "Epoch 210 Count: 300 loss: 1.4312024865831647 \t 284 loss_val: 6.8053391822746825\n",
      "Epoch 211 Count: 300 loss: 1.3576155096292495 \t 284 loss_val: 7.068083568130221\n",
      "Epoch 212 Count: 300 loss: 1.401316293648311 \t 284 loss_val: 7.0662432040487015\n",
      "Finished Training\n",
      "Training Accuracy  [27.945959399684867, 37.80835617260857, 42.68701515464845, 45.62922180227866, 48.218663877361365, 49.79734788642145, 51.5261444795443, 53.007255308963586, 54.39579671154417, 55.59919926044734, 56.6499873488867, 57.66825104411246, 58.613960323707886, 59.65974465934515, 59.96247170387173, 61.175881758379084, 61.881410903474084, 62.62947194738686, 63.09982471078353, 63.75031257505552, 64.35326478770762, 64.69101810184884, 65.2689515504905, 65.75431557229344, 66.2246683356901, 66.84012993034744, 67.08531381764996, 67.76832607513555, 67.81836360315646, 68.0535399848548, 68.78909164676234, 69.10432807329416, 68.81160853437176, 69.65974463432639, 70.01000733047285, 70.32024000420256, 70.36277190302035, 70.81811340801073, 70.71553647556784, 71.01325976729233, 71.64623449675699, 71.69627202477791, 71.90642964246578, 72.18163604658085, 72.14160602416412, 72.787090135634, 73.15236409018674, 72.949712101702, 73.46009488751541, 73.25243914622858, 73.80785570726081, 73.83037259487023, 74.3282459986784, 74.11058275178739, 74.15811840340726, 74.67850869482486, 74.77608187446565, 74.91868882932528, 75.11883894140897, 75.49161852516484, 75.47660726675855, 75.5491616823889, 75.6142104688161, 75.84688497411338, 75.81436058089977, 76.0870651086138, 76.45734281596863, 76.45484093956757, 76.59494601802616, 76.68251169206277, 76.64248166964603, 76.8901674333496, 77.1453588262563, 77.19289447787618, 77.14786070265734, 77.13785319705316, 77.5681759380331, 77.82086545453875, 77.83087296014293, 78.09356998225277, 78.01100806101825, 77.94595927459105, 78.31373510554482, 78.28871634153437, 78.32124073474796, 78.40380265598249, 78.3937951503783, 79.14185619429108, 78.87665729578019, 79.18939184591096, 78.97172859901995, 79.22441811552561, 79.15936932909841, 78.92419294740007, 79.02927175624401, 79.39704758719779, 79.67725774411495, 79.25444063233816, 79.42707010401034, 79.71478589013064, 79.58969207007833, 79.57968456447415, 79.7673252945526, 79.98498854144361, 79.68476337331809, 80.13259924910534, 80.07505609188128, 80.30773059717856, 80.00750542905303, 80.37277938360576, 80.21766304674091, 80.46034505764237, 80.31773810278274, 80.76307210216895, 80.51288446206435, 80.71553645054908, 80.50287695646016, 80.56042011368422, 80.77808336057522, 81.02827100067984, 81.06079539389344, 80.78308711337732, 80.9882409782631, 80.96572409065368, 80.9882409782631, 81.11583667471645, 81.14085543872692, 81.3134849103991, 81.33850367440955, 81.16087044993527, 81.3134849103991, 81.26094550597712, 80.97573159625787, 81.5961969437173, 81.42606934844616, 81.68126074135287, 81.58618943811311, 81.67375511214973, 81.96647465107212, 81.58618943811311, 82.00400279708781, 81.67375511214973, 81.58118568531103, 81.73880389857693, 81.95896902186898, 81.93645213425957, 81.58618943811311, 82.08906659472338, 81.97398028027526, 81.96147089827004, 81.80885643780621, 81.86639959503027, 82.16412288675477, 82.22666979678091, 82.26419794279661, 82.21416041477569, 82.40930677405728, 82.4218161560625, 82.33675235842695, 82.40430302125519, 82.41180865045833, 82.4268199088646, 82.38678988644787, 82.14660975194744, 82.39429551565101, 82.31923922361962, 82.56942686372423, 82.70202631297967, 82.57443061652633, 82.6870150545734, 82.6494869085577, 82.53940434691168, 82.57943436932841, 82.94971207668324, 82.65949441416188, 82.5619212345211, 82.7845882342142, 82.55441560531796, 82.88216141385499, 82.82211638022989, 82.86464827904767, 82.8771576610529, 83.11733779555333, 83.0022514811052, 82.85464077344349, 82.89717267226126, 82.81711262742779, 82.72454320058908, 82.99974960470416, 82.92469331267277, 83.0022514811052, 83.14235655956378, 83.06980214393344, 83.3224916604391, 82.88466329025604, 83.23992973920458, 83.32999728964225, 83.07730777313658, 83.33750291884539, 83.4150610872778, 83.23492598640249, 83.28246163802237, 83.09982466074601, 83.27245413241819, 83.38003481766316, 83.22241660439727, 83.45509110969455, 83.5551661657364, 83.30497852563178, 83.43757797488722, 83.74781064861695, 83.63022245776777]\n",
      "validation Accuracy [34.49624060150376, 40.340852130325814, 44.310776942355886, 46.81704260651629, 48.340852130325814, 49.99498746867168, 51.21804511278196, 52.771929824561404, 54.636591478696744, 55.32832080200501, 56.02005012531328, 55.8796992481203, 57.51378446115288, 58.97744360902256, 59.3984962406015, 59.86967418546366, 60.26065162907268, 61.07268170426065, 61.41353383458647, 60.87218045112782, 61.91478696741854, 61.81453634085213, 62.265664160401, 63.54887218045113, 63.83959899749373, 63.528822055137844, 64.49122807017544, 64.35087719298245, 64.50125313283208, 64.70175438596492, 65.32330827067669, 65.42355889724311, 65.99498746867168, 65.95488721804512, 65.96491228070175, 65.99498746867168, 66.19548872180451, 66.63659147869674, 67.36842105263158, 67.62907268170426, 67.12781954887218, 67.59899749373433, 68.08020050125313, 67.31829573934837, 67.468671679198, 67.91979949874687, 68.58145363408521, 68.25062656641605, 67.69924812030075, 68.82205513784461, 67.96992481203007, 69.03258145363408, 68.58145363408521, 68.94235588972431, 69.40350877192982, 68.64160401002506, 69.16290726817043, 69.47368421052632, 69.55388471177945, 70.06516290726817, 69.89473684210526, 69.6842105263158, 69.71428571428571, 69.52380952380952, 70.88721804511279, 70.03508771929825, 70.24561403508773, 70.32581453634086, 70.89724310776943, 70.57644110275689, 70.22556390977444, 69.93483709273183, 70.66666666666667, 70.46616541353383, 71.04761904761905, 71.12781954887218, 71.13784461152882, 71.16791979949875, 70.58646616541354, 70.47619047619048, 71.23809523809524, 72.04010025062657, 71.48872180451127, 71.9498746867168, 71.71929824561404, 71.23809523809524, 71.6390977443609, 71.53884711779449, 71.54887218045113, 70.7468671679198, 72.27067669172932, 71.67919799498746, 72.04010025062657, 72.33082706766918, 71.28822055137844, 71.83959899749374, 71.42857142857143, 71.25814536340852, 71.79949874686717, 71.55889724310777, 72.31077694235589, 71.73934837092732, 71.62907268170426, 72.29072681704261, 71.74937343358395, 72.04010025062657, 72.31077694235589, 72.45112781954887, 71.84962406015038, 72.9624060150376, 71.65914786967419, 71.68922305764411, 72.75187969924812, 72.64160401002506, 72.79197994987469, 72.37092731829574, 72.02005012531329, 72.73182957393483, 72.74185463659148, 72.51127819548873, 72.63157894736842, 72.83208020050125, 72.31077694235589, 72.51127819548873, 72.78195488721805, 72.7218045112782, 72.43107769423558, 72.71177944862156, 72.89223057644111, 72.94235588972431, 72.43107769423558, 72.45112781954887, 72.1203007518797, 72.73182957393483, 72.3609022556391, 73.63408521303258, 72.70175438596492, 72.69172932330827, 73.09273182957394, 72.76190476190476, 72.15037593984962, 73.22305764411027, 72.33082706766918, 73.38345864661655, 72.51127819548873, 73.02255639097744, 73.52380952380952, 73.3734335839599, 73.12280701754386, 73.27318295739349, 73.30325814536342, 72.76190476190476, 72.68170426065163, 72.68170426065163, 72.79197994987469, 72.71177944862156, 73.54385964912281, 73.19298245614036, 73.81453634085213, 73.71428571428571, 72.9624060150376, 73.58395989974937, 73.6140350877193, 73.22305764411027, 73.32330827067669, 73.10275689223057, 72.91228070175438, 73.48370927318295, 73.42355889724311, 73.05263157894737, 72.95238095238095, 73.29323308270676, 73.15288220551379, 73.31328320802005, 72.9624060150376, 73.27318295739349, 73.54385964912281, 73.22305764411027, 73.67418546365914, 73.96491228070175, 73.23308270676692, 72.91228070175438, 73.38345864661655, 73.67418546365914, 72.79197994987469, 73.31328320802005, 73.0827067669173, 73.91478696741855, 73.76441102756893, 73.44360902255639, 72.92230576441102, 72.84210526315789, 72.52130325814537, 73.79448621553885, 73.4937343358396, 73.52380952380952, 73.92481203007519, 73.81453634085213, 73.45363408521304, 73.38345864661655, 73.92481203007519, 73.30325814536342, 73.98496240601504, 74.02506265664161, 73.70426065162907, 73.65413533834587, 73.79448621553885, 73.71428571428571, 73.3734335839599, 73.69423558897243, 73.40350877192982, 73.9047619047619]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: 73.77443609022556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nplt.figure()\\nplt.plot(x_t,traincost, \\'b\\', label = \\'traincost\\')\\nplt.plot(x_v,valcost, \\'r\\', label = \\'valcost\\')\\nplt.legend()\\nplt.savefig(\"test1.png\")\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3113ca9cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainacc=[]\n",
    "valacc=[]\n",
    "testacc = []\n",
    "traincost = []\n",
    "valcost = []\n",
    "epoch_count = 250\n",
    "num = epoch_count\n",
    "batch_size_len = 35\n",
    "\n",
    "train = \"\"\n",
    "print(\"Start\", flush=True)\n",
    "for epoch in range(num):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    running_loss_val = 0.0\n",
    "    train_accuracy = 0.0\n",
    "    val_accuracy = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    #print(epoch, flush=True)\n",
    "    abcd_train = get_batch(X_Train, Y_Train,batch_size_len)\n",
    "    for i, idx in enumerate(abcd_train, 0):\n",
    "        # get the inputs\n",
    "        x_batch = [X_Train.T[index] for index in idx]\n",
    "        y_batch = [Y_Train.T[index] for index in idx]\n",
    "        #print(len(x_batch))\n",
    "        '''\n",
    "        x_batch = x_batch + [X_Train.T[index][::-1] for index in idx]\n",
    "        y_batch = y_batch + [Y_Train.T[index] for index in idx]\n",
    "        #print(len(x_batch))\n",
    "        '''\n",
    "        x_batch = np.asarray(x_batch)\n",
    "        y_batch = np.asarray(y_batch)\n",
    "        y_batch_onehot = get_one_hot(y_batch,10)\n",
    "        x_batch = x_batch.reshape(x_batch.shape[0],3,32,32)\n",
    "        input_tensor = torch.from_numpy(x_batch)\n",
    "        label_tensor = torch.from_numpy(y_batch_onehot)\n",
    "        inputs = Variable(input_tensor.cuda()).float()\n",
    "        labels = Variable(label_tensor.cuda()).long()\n",
    "        true_labels = torch.max(labels,1)[1]\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, torch.max(labels, 1)[1])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.data[0]\n",
    "        if i % 100 == 99:    # print every 2000 mini-batches\n",
    "            if(i+1 == 300):\n",
    "                #print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 100), flush=True)\n",
    "                #train = train + str(epoch + 1) + \", \" + str(i + 1) + \", loss=\" + str(running_loss / 100) + \"; \"\n",
    "                print(\"Epoch\", epoch + 1, \"Count:\", i + 1, \"loss:\", running_loss/(batch_size_len*1.0), end=' ')\n",
    "            traincost.append(running_loss / (batch_size_len*1.0))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "        _, predicted_train = torch.max(outputs.data, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted_train == true_labels.data.long()).sum()\n",
    "    train_accuracy = 100 * correct_train / (total_train + 0.0001)\n",
    "        \n",
    "    abcd = get_batch(X_Val, Y_Val,batch_size_len)\n",
    "#     for l in abcd:\n",
    "#         print(len(l), end=' ')\n",
    "#     print(\"\")\n",
    "    for i, idx in enumerate(abcd, 0):\n",
    "        # get the inputs\n",
    "        x_batch_val = [X_Val.T[index] for index in idx]\n",
    "        y_batch_val = [Y_Val.T[index] for index in idx]\n",
    "        x_batch_val = np.asarray(x_batch_val)\n",
    "        y_batch_val = np.asarray(y_batch_val)\n",
    "        y_batch_onehot_val = get_one_hot(y_batch_val,10)\n",
    "        x_batch_val = x_batch_val.reshape(x_batch_val.shape[0],3,32,32)\n",
    "        input_tensor_val = torch.from_numpy(x_batch_val)\n",
    "        label_tensor_val = torch.from_numpy(y_batch_onehot_val)\n",
    "        inputs_val = Variable(input_tensor_val.cuda()).float()\n",
    "        labels_val = Variable(label_tensor_val.cuda()).long()\n",
    "        true_labels_val = torch.max(labels_val,1)[1]\n",
    "        optimizer.zero_grad()\n",
    "        outputs_val = net(inputs_val)\n",
    "        loss_val = criterion(outputs_val, torch.max(labels_val, 1)[1])\n",
    "        running_loss_val += loss_val.data[0]\n",
    "#         if(i > 97):\n",
    "#             print(\"Hello\", i)\n",
    "        if i == len(abcd) - 1:    # print every 2000 mini-batches\n",
    "            test_accuracy = test_acc()\n",
    "            print(\"\\t\", i, \"loss_val:\", running_loss_val/(batch_size_len*1.0))#, \"Test:\", test_accuracy)\n",
    "            valcost.append(running_loss_val/(batch_size_len*1.0))\n",
    "            running_loss_val = 0.0\n",
    "        \n",
    "        _, predicted_val = torch.max(outputs_val.data, 1)\n",
    "        total_val += labels_val.size(0)\n",
    "        correct_val += (predicted_val == true_labels_val.data.long()).sum()\n",
    "    val_accuracy = 100 * correct_val / total_val\n",
    "    trainacc.append(train_accuracy)\n",
    "    valacc.append(val_accuracy)\n",
    "    testacc.append(test_accuracy)\n",
    "    if(test_accuracy>=74.0):\n",
    "        break\n",
    "    \n",
    "print('Finished Training', flush=True)\n",
    "print('Training Accuracy ',trainacc, flush=True)\n",
    "print('validation Accuracy',valacc, flush=True)\n",
    "print(\"Test:\", test_acc(), flush=True)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(trainacc, 'r', label ='train-accuracy')\n",
    "plt.plot(valacc, 'b', label = 'val-accuracy')\n",
    "plt.plot(testacc, 'g', label = 'test-accuracy')\n",
    "plt.legend()\n",
    "plt.savefig(\"test.png\")\n",
    "\n",
    "\n",
    "x_t = []\n",
    "x_v = []\n",
    "\n",
    "for i in range(len(traincost)):\n",
    "    x_t.append((i+1)*batch_size_len)\n",
    "\n",
    "for i in range(len(valcost)):\n",
    "    x_v.append((i+1)*batch_size_len)\n",
    "'''\n",
    "plt.figure()\n",
    "plt.plot(x_t,traincost, 'b', label = 'traincost')\n",
    "plt.plot(x_v,valcost, 'r', label = 'valcost')\n",
    "plt.legend()\n",
    "plt.savefig(\"test1.png\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34.49624060150376, 40.340852130325814, 44.310776942355886, 46.81704260651629, 48.340852130325814, 49.99498746867168, 51.21804511278196, 52.771929824561404, 54.636591478696744, 55.32832080200501, 56.02005012531328, 55.8796992481203, 57.51378446115288, 58.97744360902256, 59.3984962406015, 59.86967418546366, 60.26065162907268, 61.07268170426065, 61.41353383458647, 60.87218045112782, 61.91478696741854, 61.81453634085213, 62.265664160401, 63.54887218045113, 63.83959899749373, 63.528822055137844, 64.49122807017544, 64.35087719298245, 64.50125313283208, 64.70175438596492, 65.32330827067669, 65.42355889724311, 65.99498746867168, 65.95488721804512, 65.96491228070175, 65.99498746867168, 66.19548872180451, 66.63659147869674, 67.36842105263158, 67.62907268170426, 67.12781954887218, 67.59899749373433, 68.08020050125313, 67.31829573934837, 67.468671679198, 67.91979949874687, 68.58145363408521, 68.25062656641605, 67.69924812030075, 68.82205513784461, 67.96992481203007, 69.03258145363408, 68.58145363408521, 68.94235588972431, 69.40350877192982, 68.64160401002506, 69.16290726817043, 69.47368421052632, 69.55388471177945, 70.06516290726817, 69.89473684210526, 69.6842105263158, 69.71428571428571, 69.52380952380952, 70.88721804511279, 70.03508771929825, 70.24561403508773, 70.32581453634086, 70.89724310776943, 70.57644110275689, 70.22556390977444, 69.93483709273183, 70.66666666666667, 70.46616541353383, 71.04761904761905, 71.12781954887218, 71.13784461152882, 71.16791979949875, 70.58646616541354, 70.47619047619048, 71.23809523809524, 72.04010025062657, 71.48872180451127, 71.9498746867168, 71.71929824561404, 71.23809523809524, 71.6390977443609, 71.53884711779449, 71.54887218045113, 70.7468671679198, 72.27067669172932, 71.67919799498746, 72.04010025062657, 72.33082706766918, 71.28822055137844, 71.83959899749374, 71.42857142857143, 71.25814536340852, 71.79949874686717, 71.55889724310777, 72.31077694235589, 71.73934837092732, 71.62907268170426, 72.29072681704261, 71.74937343358395, 72.04010025062657, 72.31077694235589, 72.45112781954887, 71.84962406015038, 72.9624060150376, 71.65914786967419, 71.68922305764411, 72.75187969924812, 72.64160401002506, 72.79197994987469, 72.37092731829574, 72.02005012531329, 72.73182957393483, 72.74185463659148, 72.51127819548873, 72.63157894736842, 72.83208020050125, 72.31077694235589, 72.51127819548873, 72.78195488721805, 72.7218045112782, 72.43107769423558, 72.71177944862156, 72.89223057644111, 72.94235588972431, 72.43107769423558, 72.45112781954887, 72.1203007518797, 72.73182957393483, 72.3609022556391, 73.63408521303258, 72.70175438596492, 72.69172932330827, 73.09273182957394, 72.76190476190476, 72.15037593984962, 73.22305764411027, 72.33082706766918, 73.38345864661655, 72.51127819548873, 73.02255639097744, 73.52380952380952, 73.3734335839599, 73.12280701754386, 73.27318295739349, 73.30325814536342, 72.76190476190476, 72.68170426065163, 72.68170426065163, 72.79197994987469, 72.71177944862156, 73.54385964912281, 73.19298245614036, 73.81453634085213, 73.71428571428571, 72.9624060150376, 73.58395989974937, 73.6140350877193, 73.22305764411027, 73.32330827067669, 73.10275689223057, 72.91228070175438, 73.48370927318295, 73.42355889724311, 73.05263157894737, 72.95238095238095, 73.29323308270676, 73.15288220551379, 73.31328320802005, 72.9624060150376, 73.27318295739349, 73.54385964912281, 73.22305764411027, 73.67418546365914, 73.96491228070175, 73.23308270676692, 72.91228070175438, 73.38345864661655, 73.67418546365914, 72.79197994987469, 73.31328320802005, 73.0827067669173, 73.91478696741855, 73.76441102756893, 73.44360902255639, 72.92230576441102, 72.84210526315789, 72.52130325814537, 73.79448621553885, 73.4937343358396, 73.52380952380952, 73.92481203007519, 73.81453634085213, 73.45363408521304, 73.38345864661655, 73.92481203007519, 73.30325814536342, 73.98496240601504, 74.02506265664161, 73.70426065162907, 73.65413533834587, 73.79448621553885, 73.71428571428571, 73.3734335839599, 73.69423558897243, 73.40350877192982, 73.9047619047619]\n",
      "[34.54636591478697, 40.75187969924812, 43.58897243107769, 46.61654135338346, 48.94235588972431, 49.62406015037594, 51.609022556390975, 53.203007518796994, 54.39598997493734, 55.30827067669173, 56.340852130325814, 56.45112781954887, 57.333333333333336, 57.92481203007519, 60.17042606516291, 59.53884711779449, 60.76190476190476, 61.1328320802005, 61.17293233082707, 61.824561403508774, 61.984962406015036, 61.423558897243105, 62.31578947368421, 64.13032581453633, 63.62907268170426, 64.21052631578948, 64.6516290726817, 65.05263157894737, 63.959899749373434, 64.7218045112782, 64.93233082706767, 64.88220551378446, 65.32330827067669, 65.02255639097744, 65.56390977443608, 66.20551378446115, 66.24561403508773, 66.51629072681705, 67.15789473684211, 67.66917293233082, 66.90726817042606, 66.88721804511279, 67.38847117794487, 67.79949874686717, 68.20050125313283, 68.01002506265664, 68.11027568922306, 68.3609022556391, 68.06015037593986, 68.98245614035088, 68.31077694235589, 68.78195488721805, 68.74185463659148, 68.86215538847118, 69.32330827067669, 69.22305764411027, 69.1328320802005, 69.43358395989975, 69.31328320802005, 69.57393483709274, 69.19298245614036, 69.59398496240601, 69.0827067669173, 69.98496240601504, 70.06516290726817, 69.81453634085213, 69.99498746867168, 70.34586466165413, 70.55639097744361, 70.3358395989975, 69.59398496240601, 70.29573934837093, 70.28571428571429, 70.20551378446115, 70.99749373433583, 70.19548872180451, 70.76691729323308, 71.11779448621554, 70.55639097744361, 70.68671679197995, 70.72681704260651, 71.5187969924812, 71.84962406015038, 71.41854636591479, 71.91979949874687, 71.16791979949875, 71.13784461152882, 71.37844611528823, 71.21804511278195, 71.25814536340852, 71.21804511278195, 71.36842105263158, 71.32832080200501, 71.49874686716792, 71.08771929824562, 70.8671679197995, 71.82957393483709, 71.9298245614035, 71.38847117794487, 70.99749373433583, 71.81954887218045, 71.23809523809524, 72.531328320802, 71.41854636591479, 71.26817042606517, 72.23057644110276, 72.44110275689223, 71.7593984962406, 71.96992481203007, 72.42105263157895, 71.64912280701755, 72.62155388471177, 72.70175438596492, 72.17042606516291, 72.23057644110276, 71.73934837092732, 71.9498746867168, 72.7719298245614, 71.9498746867168, 72.32080200501254, 72.531328320802, 72.50125313283208, 72.13032581453633, 72.29072681704261, 72.52130325814537, 72.10025062656642, 72.57142857142857, 72.38095238095238, 72.98245614035088, 72.73182957393483, 72.14035087719299, 72.62155388471177, 72.34085213032581, 72.88220551378446, 72.49122807017544, 72.61152882205513, 71.8796992481203, 72.78195488721805, 72.38095238095238, 73.15288220551379, 72.61152882205513, 72.80200501253132, 71.86967418546367, 72.88220551378446, 73.09273182957394, 72.39097744360902, 72.54135338345864, 72.19047619047619, 72.76190476190476, 72.75187969924812, 73.24310776942356, 72.45112781954887, 72.531328320802, 72.42105263157895, 73.11278195488721, 72.85213032581454, 72.89223057644111, 73.09273182957394, 72.59147869674186, 73.71428571428571, 72.97243107769424, 72.9624060150376, 73.03258145363408, 73.14285714285714, 73.02255639097744, 72.63157894736842, 72.73182957393483, 73.19298245614036, 72.49122807017544, 73.38345864661655, 72.88220551378446, 73.52380952380952, 73.47368421052632, 73.21303258145363, 72.35087719298245, 72.90225563909775, 73.29323308270676, 72.99248120300751, 73.04260651629073, 72.56140350877193, 73.32330827067669, 72.41102756892231, 72.75187969924812, 73.1328320802005, 73.27318295739349, 72.87218045112782, 72.61152882205513, 72.5513784461153, 73.8546365914787, 72.89223057644111, 73.16290726817043, 73.62406015037594, 72.4812030075188, 73.41353383458646, 73.203007518797, 73.34335839598998, 73.44360902255639, 72.91228070175438, 73.41353383458646, 73.6641604010025, 72.85213032581454, 73.1829573934837, 72.6015037593985, 73.07268170426065, 73.46365914786968, 73.14285714285714, 73.82456140350877, 73.734335839599, 72.94235588972431, 72.61152882205513, 73.15288220551379, 74.20551378446115]\n"
     ]
    }
   ],
   "source": [
    "print(valacc)\n",
    "print(testacc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
